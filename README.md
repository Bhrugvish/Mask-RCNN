# Mask-RCNN
Mask RCNN using Detectron2 model 

# Installations :
<ul>
  <li>pip install Pillow</li>
<li>pip install yacs</li>
<li>pip install PyYAML</li>
<li>pip install portalocker</li>
<li>pip install pycocotools</li>
<li>pip install termcolor</li>
<li>pip install torch torchvision</li>
<li>pip install tabulate</li>
<li>pip install cloudpickle</li>
<li>pip install opencv-python</li>
<li>pip install numpy</li>
<li>pip install ops</li>
</ul>

# Fitting the model
<p>Once image is loaded, we need to load our model and a little bit of configuration. First, we load the configurations from Detectron2, and then we apply to it a custom configuration coming from COCO- InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml. Then the threshold is set, the sensitivity of the model while detecting objects.
<p>The next step consists of loading the checkpoints relative to this model.
The next step consists in instantiating the model itself, passing to our predictor an image, which corresponds as well in an array (a 3D array to be precise: one axis for the width, another for the height and the last one representing the colors of the image).
<p>If we inspect the outputs generated by the model we are presented with a massive dictionary, this dictionary contains, the number of objects detected (num_instances), info about the image and the coordinates of the image where the box should be drawn, together with the labels (pred_classes) for each box (instance).


# Input Image :
<img src="input2.jpg" alt="Input image ">

# Getting an output image
 <p>Now we can visualize the image along with the boxes showing predicted objects in the image, the object we used is called Visualizer, once instantiated the Visualizer with our image and the metadata, we can call the draw_instance_predictions method with the outputs as argument.

# Output Image :
<img src="Output.png" alt="Output image ">

